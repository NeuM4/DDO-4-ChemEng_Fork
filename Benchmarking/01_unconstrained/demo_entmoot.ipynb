{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from entmoot import Enting, ProblemConfig, PyomoOptimizer\n",
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# # This is the function to be minimized. Usually some complicated like a simulation.\n",
    "# def my_func(x: float) -> float:\n",
    "#     return x**2 + 1 + random.uniform(-0.2, 0.2)\n",
    "\n",
    "# # Define a one-dimensional minimization problem with one real variable bounded by -2 and 3\n",
    "# problem_config = ProblemConfig()\n",
    "# problem_config.add_feature(\"real\", (-2, 3))\n",
    "# problem_config.add_min_objective()\n",
    "\n",
    "# # Create training data for the tree model\n",
    "# X_train = np.reshape(np.linspace(-2, 3, 10), (-1, 1))\n",
    "# y_train = np.reshape([my_func(x) for x in X_train], (-1, 1))\n",
    "\n",
    "# # Define Bayesian optimization parameters using an l1-distance based uncertainty measure and\n",
    "# # penalizing the distance from well-known areas, i.e. exploitation (instead of exploration)\n",
    "# params_bo = {\"unc_params\": {\"dist_metric\": \"l1\", \"acq_sense\": \"penalty\"}}\n",
    "\n",
    "# # Define an Enting object which holds information about the problem as well as the parameters...\n",
    "# enting = Enting(problem_config, params=params_bo)\n",
    "# # ... and train the underlying tree model.\n",
    "# enting.fit(X_train, y_train)\n",
    "\n",
    "# # Create an PyomoOptimizer object that solves the optimization problem using the solver \"GLPK\"\n",
    "# params_pyo = {\"solver_name\": \"glpk\"}\n",
    "# opt_pyo = PyomoOptimizer(problem_config, params=params_pyo)\n",
    "# res = opt_pyo.solve(enting)\n",
    "\n",
    "# # Inspect the result. The optimal point should be close to zero.\n",
    "# print(f\"Optimal point: {res.opt_point[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation into our framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Imports #\n",
    "###########\n",
    "\n",
    "# importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "# importing algorithms\n",
    "from BFGS_multistart import*\n",
    "from Stochastic_local_search import*\n",
    "from Cuadratic_opt_v2 import *\n",
    "from Scipy_opt_algs import*\n",
    "from BO_NpScpy import*\n",
    "# importing test functions\n",
    "from test_function import*\n",
    "from utils import *\n",
    "from COBYQA import *\n",
    "from ScikitQuant_opt_algs import *\n",
    "from pySOT_opt_algs import *\n",
    "from CUATRO import *\n",
    "from ENTMOOT import *\n",
    "\n",
    "\n",
    "##########################\n",
    "# Algorithms & Functions #\n",
    "##########################\n",
    "\n",
    "home_dir  = 'images/trajectory_plots_1D_&_tables'\n",
    "\n",
    "algorithms_test = [\n",
    "    # LS_QM_v2,\n",
    "    # opt_SnobFit,\n",
    "    # opt_SRBF,\n",
    "    # opt_DYCORS,\n",
    "    # opt_SOP,\n",
    "    # opt_COBYLA,\n",
    "    # COBYQA,\n",
    "    # opt_CUATRO,\n",
    "# # # Feel free to add these commented-out algorithms as a further test,\n",
    "# # # however, do note they are more time-consuming to run\n",
    "# BO_np_scipy,\n",
    "opt_ENTMOOT,\n",
    "]\n",
    "\n",
    "functions_test  = [  #!!! Multimodal before Unimodal!!!\n",
    "    'Levy_f',\n",
    "    'Ackley_f',\n",
    "    'Rosenbrock_f',\n",
    "    'Antonio_f',\n",
    "    ]\n",
    "\n",
    "multim  = ['Levy_f', 'Ackley_f']\n",
    "unim    = ['Rosenbrock_f', 'Antonio_f']\n",
    "\n",
    "###########################\n",
    "# Optimization parameters #\n",
    "###########################\n",
    "\n",
    "N_x_l        = [\n",
    "    2,\n",
    "    5,\n",
    "    7,\n",
    "    ]               # Number of input dimensions\n",
    "\n",
    "start_       = [5, 10, 15]              # starting points on the trajectory of the algorithm on the test function\n",
    "\n",
    "reps         = 5                        # We run each algorithm 5 times on each objective function. The number of evaluations per run is given by f_eval_l\n",
    "f_eval_l     = [\n",
    "    20,\n",
    "    50,\n",
    "    100\n",
    "    ]  # These are the number of function evaluations (length of trajectory) foreach run in reps. The number depends on the input dimension N_x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shift = np.array([[-0.65436022], [ 2.09921755]])\n",
    "n_x = 2\n",
    "bounds = np.array([[-7., 7.], [-7., 7.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = Test_function(\n",
    "    x_shift=x_shift,\n",
    "    func_type='Rosenbrock_f', \n",
    "    n_x=n_x, \n",
    "    track_x=False, \n",
    "    bounds=bounds\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### our version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entmoot import Enting, ProblemConfig, GurobiOptimizer\n",
    "import numpy as np\n",
    "\n",
    "# define problem\n",
    "problem_config = ProblemConfig(rnd_seed=1234)\n",
    "\n",
    "# specify dimensions and ranges\n",
    "for d_ in range(n_x):\n",
    "\n",
    "    bounds_tuple = tuple(bounds[d_])\n",
    "    problem_config.add_feature(\"real\", bounds_tuple)\n",
    "\n",
    "# specify goal\n",
    "# CHECK HERE IF THIS IS THE CORRECT DIRECTION\n",
    "problem_config.add_min_objective()\n",
    "\n",
    "# specify initial no. of samples\n",
    "N_init_samples = 15\n",
    "\n",
    "# generate initial samples\n",
    "train_y,train_x = Random_searchENT(t_.fun_test, n_p=n_x, bounds_rs=bounds, iter_rs=N_init_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training-dataset in the form required for the fit method of enting\n",
    "# x is a list of tuples, which represent one datapoint each. A 2D-problem has 2 entries per tuple\n",
    "# y is a numpy array of shape (n_points, 1)\n",
    "\n",
    "train_y_cust = train_y.reshape((len(train_y),1))\n",
    "train_x_cust = list(zip(*train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-05-22\n",
      "Set parameter MIPGap to value 0\n",
      "129.6753709787268\n",
      "Set parameter MIPGap to value 0\n",
      "79.76561030015527\n",
      "Set parameter MIPGap to value 0\n",
      "301.24340957872136\n",
      "Set parameter MIPGap to value 0\n",
      "170.96358656301746\n",
      "Set parameter MIPGap to value 0\n",
      "108.8238459128776\n",
      "Set parameter MIPGap to value 0\n",
      "103.7483072294721\n",
      "Set parameter MIPGap to value 0\n",
      "55.22615037771871\n",
      "Set parameter MIPGap to value 0\n",
      "83.602789391827\n",
      "Set parameter MIPGap to value 0\n",
      "101.48685307528652\n",
      "Set parameter MIPGap to value 0\n",
      "69.5735717192311\n",
      "Set parameter MIPGap to value 0\n",
      "108.80132609915931\n",
      "Set parameter MIPGap to value 0\n",
      "79.34768764142781\n",
      "Set parameter MIPGap to value 0\n",
      "66.7338839934547\n",
      "Set parameter MIPGap to value 0\n",
      "72.78123507857221\n",
      "Set parameter MIPGap to value 0\n",
      "61.224251104273954\n",
      "Set parameter MIPGap to value 0\n",
      "57.91055901340951\n",
      "Set parameter MIPGap to value 0\n",
      "71.50042577253711\n",
      "Set parameter MIPGap to value 0\n",
      "55.485753144164796\n",
      "Set parameter MIPGap to value 0\n",
      "57.82708580369127\n",
      "Set parameter MIPGap to value 0\n",
      "61.20846047488538\n",
      "Set parameter MIPGap to value 0\n",
      "56.08511539424814\n",
      "Set parameter MIPGap to value 0\n",
      "59.49277198668612\n",
      "Set parameter MIPGap to value 0\n",
      "56.8111632408585\n",
      "Set parameter MIPGap to value 0\n",
      "66.43418100580453\n",
      "Set parameter MIPGap to value 0\n",
      "56.235254950193145\n",
      "Set parameter MIPGap to value 0\n",
      "56.4301945959706\n",
      "Set parameter MIPGap to value 0\n",
      "54.30518346666395\n",
      "Set parameter MIPGap to value 0\n",
      "54.959576594516165\n",
      "Set parameter MIPGap to value 0\n",
      "54.237397735667614\n",
      "Set parameter MIPGap to value 0\n",
      "60.86062088455068\n",
      "Set parameter MIPGap to value 0\n",
      "55.67181827579214\n",
      "Set parameter MIPGap to value 0\n",
      "55.72776653109257\n",
      "Set parameter MIPGap to value 0\n",
      "60.07800883721649\n",
      "Set parameter MIPGap to value 0\n",
      "54.965901642423454\n",
      "Set parameter MIPGap to value 0\n",
      "58.09545522383654\n",
      "Set parameter MIPGap to value 0\n",
      "55.01510790773175\n",
      "Set parameter MIPGap to value 0\n",
      "54.38409436838969\n",
      "Set parameter MIPGap to value 0\n",
      "55.719255060613634\n",
      "Set parameter MIPGap to value 0\n",
      "55.269623778048114\n",
      "Set parameter MIPGap to value 0\n",
      "55.45828583453376\n",
      "Set parameter MIPGap to value 0\n",
      "55.25519570426802\n",
      "Set parameter MIPGap to value 0\n",
      "55.05110212410288\n",
      "Set parameter MIPGap to value 0\n",
      "55.38277949095281\n",
      "Set parameter MIPGap to value 0\n",
      "56.132634465062694\n",
      "Set parameter MIPGap to value 0\n",
      "55.505763006754904\n",
      "Set parameter MIPGap to value 0\n",
      "55.2852627560374\n",
      "Set parameter MIPGap to value 0\n",
      "55.15528500737915\n",
      "Set parameter MIPGap to value 0\n",
      "55.37464380851978\n",
      "Set parameter MIPGap to value 0\n",
      "55.30752003299157\n",
      "Set parameter MIPGap to value 0\n",
      "64.7335136181709\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### their version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def blackbox_ground_truth(x: np.ndarray, noise_std: float = 0.02) -> np.ndarray:\n",
    "#     \"\"\"Get the ground truth response for each observation in a dataset\n",
    "\n",
    "#     The input array is N_observations x N_input_features and the output\n",
    "#     of this function is a column vector with N_observations elements\n",
    "\n",
    "#     Note for Nathan: I think this problem I invented is not a good one\n",
    "#     to demonstrate GBT complexity. I'm sure you have a better idea.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def evaluate_blackbox_single_obs(\n",
    "#         xin: np.ndarray\n",
    "#     ) -> np.ndarray:\n",
    "#         return (\n",
    "#             xin[0]\n",
    "#             + 0.25 * xin[1] * xin[2]\n",
    "#             - 0.33 * xin[0] * xin[1] * xin[2]\n",
    "#             + 0.2 * xin[3]\n",
    "#             - 0.5 * xin[1] * xin[3]\n",
    "#             + np.sin(4.0 * xin[1] * np.pi)\n",
    "#             + np.cos(4.0 * xin[0] * xin[3] * np.pi)\n",
    "#             + (xin[1] - 0.6) ** 2\n",
    "#             + (xin[3] - 0.2) ** 2\n",
    "#             + (xin[2] - 0.85)**2\n",
    "#             + np.random.normal(loc=0, scale=noise_std)\n",
    "#             + xin[0]*np.exp(xin[1] * xin[2])\n",
    "#         )\n",
    "\n",
    "#     return np.array([evaluate_blackbox_single_obs(xobs) for xobs in x]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from entmoot import Enting, ProblemConfig, GurobiOptimizer\n",
    "# import numpy as np\n",
    "\n",
    "# # define problem\n",
    "# problem_config = ProblemConfig(rnd_seed=1234)\n",
    "# problem_config.add_feature(\"real\", (-4, 4))\n",
    "# problem_config.add_feature(\"real\", (-4, 4))\n",
    "# problem_config.add_feature(\"real\", (-4, 4))\n",
    "# problem_config.add_feature(\"real\", (-4, 4))\n",
    "# problem_config.add_min_objective()\n",
    "\n",
    "# # sample data for training. This is the intial dataset from before the\n",
    "# # iterative optimization starts. Let's make it more interesting by avoiding\n",
    "# # any really good points (obj < 0) during the initial sampling. Do this in a\n",
    "# # quick and dirty way assuming that we will randomly generate enough samples\n",
    "\n",
    "# N_init_samples = 15\n",
    "# train_x = problem_config.get_rnd_sample_list(num_samples=N_init_samples * 100)\n",
    "# # train_y,train_x = Random_searchENT(blackbox_ground_truth, n_p=n_x, bounds_rs=bounds, iter_rs=N_init_samples)\n",
    "\n",
    "# train_y = blackbox_ground_truth(train_x) # supposed to be a numpy array of shape (N_init_samples,1)\n",
    "# keep = train_y > 0\n",
    "# train_x = [train_x[idx] for idx, k in enumerate(keep) if k][:N_init_samples]\n",
    "# train_y = train_y[keep][:N_init_samples].reshape(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "# import gurobipy as gp\n",
    "\n",
    "# N_iterations = 50\n",
    "# params = {\"unc_params\": {\"dist_metric\": \"l1\", \"acq_sense\": \"exploration\", \"beta\": 1.5}}\n",
    "# enting = Enting(problem_config, params=params)\n",
    "# params_gurobi = {\"MIPGap\": 0, \"OutputFlag\": 0}\n",
    "# opt_gur = GurobiOptimizer(problem_config, params=params_gurobi)\n",
    "\n",
    "# # Remember the proposals and outcomes in these variables\n",
    "# opt_trajectory_inputs = []\n",
    "# opt_trajectory_outputs = np.empty((N_iterations, 1))\n",
    "\n",
    "# # train_x and train_y are from before\n",
    "\n",
    "\n",
    "# for idx in range(N_iterations):\n",
    "#     # Put together the initial dataset and any optimization iterations\n",
    "#     # we have done so far\n",
    "#     x = [_ for _ in chain(train_x, opt_trajectory_inputs)]\n",
    "#     y = np.concatenate(\n",
    "#         (train_y, opt_trajectory_outputs[:idx, :]), axis=0\n",
    "#     )\n",
    "\n",
    "\n",
    "#     enting.fit(x, y) \n",
    "#     res_gur = opt_gur.solve(enting)\n",
    "#     opt_trajectory_inputs.append(tuple(xopt for xopt in res_gur.opt_point)) # opt_point is a list of length n_x (dimensions of x)\n",
    "#     print(blackbox_ground_truth(opt_trajectory_inputs)[-1,0])\n",
    "#     opt_trajectory_outputs[idx, 0] = blackbox_ground_truth(opt_trajectory_inputs)[-1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Very dense sampling to find the optimum empirically for later comparison\n",
    "# N_dense_samples = 100000\n",
    "# dense_sample = problem_config.get_rnd_sample_list(num_samples=N_dense_samples)\n",
    "# dense_sample_outcomes = blackbox_ground_truth(dense_sample, noise_std=0)\n",
    "\n",
    "# opt_objval = np.min(dense_sample_outcomes)\n",
    "# print(\n",
    "#     f\"Function has a minimum value of approx {np.round(opt_objval ,decimals=3)}\",\n",
    "#     f\" at position \\n{[np.round(x, decimals=3) for x in dense_sample[np.argmin(dense_sample_outcomes)]]}\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddopt_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
